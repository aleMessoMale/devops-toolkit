# Source: https://gist.github.com/4e75e84de9e0f503fb95fdf312de1051

##############################################
# Using Argo Rollouts To Deploy Applications #
##############################################

############################################
# Installing And Configuring Argo Rollouts #
############################################

# Docker Desktop (docker-istio.sh): https://gist.github.com/a3025923ad025215fe01594f937d4298)
# Minikube (minikube-istio.sh): https://gist.github.com/1ab5f877852193e8ebd33a97ae170612)
# GKE (gke-istio.sh): https://gist.github.com/d5c93afc83535f0b5fec93bd03e447f4)
# EKS (eks-istio.sh): https://gist.github.com/2ebbabc3ff515ed27b2e46c0201fb1f8)
# AKS (aks-istio.sh): https://gist.github.com/2ec945256e3901fee1a62bb04d8b53b0)

Parti da un cluster funzionante con un ingress controller e istio -> vedi link sopra per EKS che ho copiato nel file:
2.Install-Cluster-And-Argo-Rollout.MD

# If macOS
brew install \
argoproj/tap/kubectl-argo-rollouts

# Scarichiamo e installiamo argo-rollouts in locale e nel cluster k8s (versione client e server immagino)
# If Linux or WSL
curl -LO https://github.com/argoproj/argo-rollouts/releases/download/v0.9.1/kubectl-argo-rollouts-linux-amd64
# If Linux or WSL
chmod +x kubectl-argo-rollouts-linux-amd64
# If Linux or WSL
sudo mv ./kubectl-argo-rollouts-linux-amd64 \
/usr/local/bin/kubectl-argo-rollouts

kubectl argo rollouts --help

# creiamo namespace per installare argo rollout
kubectl create namespace argo-rollouts
# lo installiamo nel cluster
kubectl --namespace argo-rollouts apply \
--filename https://raw.githubusercontent.com/argoproj/argo-rollouts/stable/manifests/install.yaml

git clone https://github.com/vfarcic/devops-toolkit.git

cd devops-toolkit

git pull

cat helm/templates/rollout.yaml

cat helm/templates/hpa.yaml

cat helm/templates/istio.yaml

cat helm/values.yaml

###############################
# Deploying The First Release #
###############################

cat rollout/values-pause-x2.yaml

# installiamo l'helm chart chiamato devops-toolkit, con l'installazione presente nella folder helm
# installiamo nel namespace devops-toolkit, lo creiamo se non presente, utilizziamo i valori presenti in
# rollout/values-pause-x2, impostiamo l'ingress ad hoc e il tag dell'immagine che installiamo è il 2.6.2
# ne scegliamo uno vecchio così vediamo poi i progressi e attendiamo fino al termine dell'installazione
helm upgrade --install \
devops-toolkit helm \
--namespace devops-toolkit \
--create-namespace \
--values rollout/values-pause-x2.yaml \
--set ingress.host=devops-toolkit.$ISTIO_HOST.nip.io \
--set image.tag=2.6.2 \
--wait

# questo non credo l'abbia eseguito (uguale all'altro senza ingress)
helm upgrade --install \
devops-toolkit helm \
--namespace devops-toolkit \
--create-namespace \
--values rollout/values-pause-x2.yaml \
--set image.tag=2.6.2 \
--wait

# eseguiamo il comando tramite kubectl argo rollout per ottenere gli oggetti di tipologia rollout
# avendo installato argocd rollout, probabilmente abbiamo un'estensione anche dei comandi kubectl

# come vediamo il rollout si comporta come un Deployment, crea un ReplicaSet e dei Pod dietro
# non essendoci altre release, la prima volta che deployamo un'applicazione, gli step sono ignorati da argo rollout
# e dati per completati. infatti qua segna 8/8, ma non ha atteso alcuno sblocco nostro manuale 
# naturalmente il canary deployment ha senso solo quando si hanno più release
kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

# If NOT Minikube
open http://devops-toolkit.$ISTIO_HOST.nip.io

####################################################
# Deploying New Releases Using The Canary Strategy #
####################################################

# portiamo avanti la release, ne installiamo una seconda, così vediamo in azione la parte di argo rollout
helm upgrade devops-toolkit helm \
--namespace devops-toolkit \
--reuse-values \
--set image.tag=2.9.9

# diamo quindi un occhio, dopo l'installazione, allo stato dell'oggetto rollout
# quello che vediamo è che ha effettuato i primi 2 step, redirige il traffico al 20% sulla canary e 80% sulla stable e
# si è stoppato in attesa di istruzioni nostre per fargli effettuare gli altri step (passaggio traffico a 40 e così via)
kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

```
acasula@osboxes:~/developmentEnv/workspaces/personal/devops-toolkit$ kubectl argo rollouts --namespace devops-toolkit get rollout devops-toolkit-devops-toolkit
Name:            devops-toolkit-devops-toolkit
Namespace:       devops-toolkit
Status:          ॥ Paused
Strategy:        Canary
Step:          1/8
SetWeight:     20
ActualWeight:  20
Images:          vfarcic/devops-toolkit-series:2.6.2 (stable)
                 vfarcic/devops-toolkit-series:2.9.9 (canary)
```

# If NOT Minikube
# quello che facciamo è fare una serie di richieste curl all'ingress (gestito da istio) e verificare che nella risposta
# alla curl, sia presente la stringa relativa al corso che è presente solo nella nuova versione per verificare che
# stia bilanciando le richieste al 20%. Effettivamente lui ottiene un 17, 
# io non riesco a raggiungere invece ed ottengo 0, non risolve l'host, da fixare
for i in {1..100}; do
curl -s http://devops-toolkit.$ISTIO_HOST.nip.io \
| grep -i "catalog, patterns, and blueprints"
done | wc -l

# If Minikube
for i in {1..100}; do
curl -s -H "Host: devopstoolkitseries.com" \
"http://$ISTIO_HOST" \
| grep -i "catalog, patterns, and blueprints"
done | wc -l

# recuperiamo i virtual service di istio in formato yaml
kubectl --namespace devops-toolkit \
get virtualservice \
devops-toolkit-devops-toolkit \
--output yaml

spec:
gateways:
- devops-toolkit-devops-toolkit
  hosts:
- devops-toolkit-devops-toolkit.local
- devops-toolkit.192.203.230.10.nip.io
  http:
- name: primary
  route:
    - destination:
      host: devops-toolkit-devops-toolkit
      port:
      number: 80
      weight: 80
    - destination:
      host: devops-toolkit-devops-toolkit-canary
      port:
      number: 80
      weight: 20

come vedi, ha un peso di 80 sulla prima destination e 20 sul canary. Lo ha modificato lui (definito tramite helm)

# andiamo quindi a fare il promote della release con il comando kubectl argo rollouts promote <application-name>
# in questo modo fondamentalmente quel che facciamo è mandare avanti la release allo step successivo (da 20 a 40 di traffico)
kubectl argo rollouts \
--namespace devops-toolkit \
promote devops-toolkit-devops-toolkit

# qua teoricamente dovrebbe esser andato al secondo step, ma non ha funzionato, almeno a me
kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

# qua verifica che stia redirigendo effettivamente il 40%
# If NOT Minikube
for i in {1..100}; do
curl -s http://devops-toolkit.$ISTIO_HOST.nip.io \
| grep -i "catalog, patterns, and blueprints"
done | wc -l

# If Minikube
for i in {1..100}; do
curl -s -H "Host: devopstoolkitseries.com" \
"http://$ISTIO_HOST" \
| grep -i "catalog, patterns, and blueprints"
done | wc -l

# qua rifa lo stesso giro, promuove e porta, verifica su k8s e poi tramite curl per l'ulteriore step
# qua verifica che ha fatto 10 secondi e dopo si è mosso verso la nuova release redirigendo nell'ultimo step il 100%
# del traffico sulla nuova release. Ha fatto gli step automaticamente avendo un tempo di 10s e non stoppandosi in attesa
# di nostri comandi

kubectl argo rollouts \
--namespace devops-toolkit \
promote devops-toolkit-devops-toolkit

kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

# If NOT Minikube
# qua abbiamo fondamentalmente il 100% del traffico sulla nuova release
for i in {1..100}; do
curl -s http://devops-toolkit.$ISTIO_HOST.nip.io \
| grep -i "catalog, patterns, and blueprints"
done | wc -l

# If Minikube
for i in {1..100}; do
curl -s -H "Host: devopstoolkitseries.com" \
"http://$ISTIO_HOST" \
| grep -i "catalog, patterns, and blueprints"
done | wc -l

#############################
# Rolling Back New Releases #
#############################

helm upgrade devops-toolkit helm \
--namespace devops-toolkit \
--reuse-values \
--set image.tag=2.9.17

kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

# Do NOT run this command
kubectl argo rollouts \
--namespace devops-toolkit \
abort devops-toolkit-devops-toolkit

helm upgrade devops-toolkit helm \
--namespace devops-toolkit \
--reuse-values \
--set image.tag=2.9.9

kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

############################################################
# Exploring Prometheus Metrics And Writing Rollout Queries #
############################################################

echo $ISTIO_HOST

# Open a second terminal session.

export ISTIO_HOST=[...]

# If NOT Minikube
while true; do
curl -I http://devops-toolkit.$ISTIO_HOST.nip.io
sleep 1
done

# If Minikube
while true; do
curl -I -H "Host: devopstoolkitseries.com" \
"http://$ISTIO_HOST"
sleep 1
done

# If WSL and `sleep` fails with `sleep: cannot read realtime clock: Invalid argument` (it's a bug in WSL 1, upgrades Ubuntu to 20.04)
sudo apt-mark hold libc6

# If WSL and `sleep` fails with `sleep: cannot read realtime clock: Invalid argument` (it's a bug in WSL 1, upgrades Ubuntu to 20.04)
sudo apt -y --fix-broken install

# If WSL and `sleep` fails with `sleep: cannot read realtime clock: Invalid argument` (it's a bug in WSL 1, upgrades Ubuntu to 20.04)
sudo apt update

# If WSL and `sleep` fails with `sleep: cannot read realtime clock: Invalid argument` (it's a bug in WSL 1, upgrades Ubuntu to 20.04)
sudo apt -y full-upgrade

# Go back to the first terminal session

helm repo add prometheus \
https://prometheus-community.github.io/helm-charts

helm upgrade --install \
prometheus prometheus/prometheus \
--namespace monitoring \
--create-namespace \
--wait

kubectl --namespace monitoring \
port-forward deployment/prometheus-server \
9090 &

open http://localhost:9090

# Prometheus query (uncomment first):
# istio_requests_total

# Prometheus query (uncomment first):
# sum(irate(
#   istio_requests_total{
#     reporter="source",
#     destination_service=~"devops-toolkit-devops-toolkit.devops-toolkit.svc.cluster.local"
#   }[2m]
# ))

# Prometheus query (uncomment first):
# sum(irate(
#   istio_requests_total{
#     reporter="source",
#     destination_service=~"devops-toolkit-devops-toolkit.devops-toolkit.svc.cluster.local",
#     response_code=~"2.*"
#   }[2m]
# )) / sum(irate(
#   istio_requests_total{
#     reporter="source",
#     destination_service=~"devops-toolkit-devops-toolkit.devops-toolkit.svc.cluster.local"
#   }[2m]
# ))

pkill kubectl

################################
# Exploring Automated Analysis #
################################

cat rollout/values-analysis.yaml

cat helm/values.yaml

cat helm/templates/rollout.yaml

kubectl delete namespace devops-toolkit

#################################################
# Deploying Releases With Fully Automated Steps #
#################################################

# If NOT Minikube
helm upgrade --install \
devops-toolkit helm \
--namespace devops-toolkit \
--create-namespace \
--values rollout/values-analysis.yaml \
--set ingress.host=devops-toolkit.$ISTIO_HOST.nip.io \
--set image.tag=2.6.2 \
--wait

# If Minikube
helm upgrade --install \
devops-toolkit helm \
--namespace devops-toolkit \
--create-namespace \
--values rollout/values-analysis.yaml \
--set image.tag=2.6.2 \
--wait

kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

# Go to the second terminal

# If NOT Minikube
while true; do
curl -I http://devops-toolkit.$ISTIO_HOST.nip.io/this-does-not-exist
sleep 1
done

# If Minikube
while true; do
curl -I -H "Host: devopstoolkitseries.com" \
"http://$ISTIO_HOST/this-does-not-exist"
sleep 1
done

# Go to the first terminal session

helm upgrade devops-toolkit helm \
--namespace devops-toolkit \
--reuse-values \
--set image.tag=2.9.9

kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

# Go to the second terminal session

# If NOT Minikube
while true; do
curl -I http://devops-toolkit.$ISTIO_HOST.nip.io
sleep 1
done

# If Minikube
while true; do
curl -I -H "Host: devopstoolkitseries.com" \
"http://$ISTIO_HOST"
sleep 1
done

helm upgrade devops-toolkit helm \
--namespace devops-toolkit \
--reuse-values \
--set image.tag=2.9.17

kubectl argo rollouts \
--namespace devops-toolkit \
get rollout devops-toolkit-devops-toolkit \
--watch

# Stop the rollout and loops in both terminals

# Go to the first terminal session

#####################
# What Happens Now? #
#####################

kubectl delete namespace devops-toolkit

kubectl delete namespace argo-rollouts

kubectl delete namespace monitoring

cd ..